{
 "metadata": {
  "name": "",
  "signature": "sha256:9b2bc346663367a646449b13f8841411cbf60ce6aefdd0751abb7dd0c45b7aea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os, re, argparse, csv\n",
      "import shutil"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WorkflowParser(object):\n",
      "    \n",
      "    def __init__(self, batch_file=None):\n",
      "        \n",
      "        self.bf = batch_file\n",
      "        self.read_batch_file()\n",
      "        \n",
      "    def read_batch_file(self):\n",
      "        \n",
      "        batch_file = self.bf\n",
      "        with open(batch_file) as f:\n",
      "            batch_lines = f.readlines()\n",
      "            \n",
      "        self.batch = batch_lines\n",
      "    \n",
      "    def get_params(self):\n",
      "        \n",
      "        param_line = [ l for l in self.batch if 'SampleName' in l ][0]\n",
      "        param_dict = { idx: re.sub('##.*', '', p) \\\n",
      "                       for idx,p in enumerate(param_line.strip().split('\\t')) }\n",
      "        \n",
      "        self.pd = param_dict\n",
      "        \n",
      "    def get_lib_params(self):\n",
      "        \n",
      "        if not hasattr(self, 'pd'):\n",
      "            self.get_params()\n",
      "        \n",
      "        param_dict = self.pd\n",
      "        lib_param_dict = [ { param_dict[i]: p \\\n",
      "                             for i,p in enumerate(l.strip().split('\\t')) } \\\n",
      "                           for l in self.batch if re.search('lib[0-9]+', l) ]\n",
      "        \n",
      "        self.lpd = lib_param_dict\n",
      "        \n",
      "    def build_out_dict(self):\n",
      "        \n",
      "        if not hasattr(self, 'lpd'):\n",
      "            self.get_lib_params()\n",
      "        \n",
      "        lib_param_dict = self.lpd\n",
      "        out_file_dict = { pd['SampleName']: { re.sub('_out', '', k): pd[k] \\\n",
      "                                              for k in pd if 'out' in k } \\\n",
      "                          for pd in lib_param_dict }\n",
      "        \n",
      "        self.ofd = out_file_dict\n",
      "        \n",
      "    def show_output_files(self):\n",
      "        \n",
      "        if not hasattr(self, 'ofd'):\n",
      "            self.build_out_dict()\n",
      "        \n",
      "        return self.ofd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ResultCurator(object):\n",
      "    def __init__(self, processed_dir=None):\n",
      "        self.dir = processed_dir\n",
      "        self.pf = re.search('Project_.*', processed_dir).group()\n",
      "\n",
      "    def get_outputs(self):\n",
      "        \n",
      "        processed_dir = self.dir\n",
      "        \n",
      "        batch_file = [ f for f in os.listdir(processed_dir) if \\\n",
      "                       re.search('v[0-9]\\.[0-9]+\\.txt', f) ]\n",
      "        \n",
      "        if len(batch_file):\n",
      "            batch_file = os.path.join(processed_dir, batch_file[0])\n",
      "\n",
      "        output_dict = WorkflowParser(batch_file).show_output_files()\n",
      "        \n",
      "        self.od = output_dict\n",
      "\n",
      "    def curate_outputs(self):\n",
      "        \n",
      "        if not hasattr(self, 'od'):\n",
      "            self.get_outputs()\n",
      "            \n",
      "        for lib in self.od:\n",
      "            sc = SampleCurator(lib, self.od[lib])\n",
      "            sc.organize_files(self.dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SampleCurator(object):\n",
      "    \n",
      "    def __init__(self, lib_id=None, output_dict=None):\n",
      "        \n",
      "        self.lib = lib_id\n",
      "        self.lod = output_dict\n",
      "    \n",
      "    def get_result_type(self, output):\n",
      "        output_str = re.sub('_[a-z]+$', '', output)\n",
      "        output_type = re.search('(?<=_)[a-z]+$', output_str)\n",
      "        if output_type:\n",
      "            result_type = output_type.group()\n",
      "        else:\n",
      "            result_type = output_str\n",
      "        \n",
      "        return result_type\n",
      "    \n",
      "    def get_result_source(self, output):\n",
      "        if not re.search('fastq$', output):\n",
      "            result_sources = ['picard_align', 'picard_markdups', 'picard_rnaseq', \n",
      "                              'htseq', 'trinity', 'tophat', 'tophat_stats', 'fastqc']\n",
      "            result_source = [ rs for rs in result_sources \\\n",
      "                              if re.search(rs.lower(), output) ][0]\n",
      "        else:\n",
      "            result_sources = ['fastq', 'trimmed_fastq']\n",
      "            result_source = [ rs for rs in result_sources \\\n",
      "                              if re.search('^' + rs.lower() + '$', output) ][0]\n",
      "            \n",
      "    def build_source_dict(self):\n",
      "        \n",
      "        output_dict = self.lod\n",
      "        \n",
      "        source_dict = {}\n",
      "\n",
      "        for o in output_dict:\n",
      "            rt = self.get_result_type(o)\n",
      "            rs = self.get_result_source(o)\n",
      "\n",
      "            if rs in source_dict:\n",
      "                source_dict[rs][o] = {'file': output_dict[o],\n",
      "                                      'type': rt}\n",
      "            else:\n",
      "                source_dict[rs] = {o: {'file': output_dict[o],\n",
      "                                       'type': rt}}\n",
      "        \n",
      "        self.sd = source_dict\n",
      "    \n",
      "    def organize_files(self, target_dir):\n",
      "        \n",
      "        if not hasattr(self, 'sd'):\n",
      "            self.build_source_dict()\n",
      "        \n",
      "        for rs in self.sd:\n",
      "            fm = FileMunger(self, target_dir, rs)\n",
      "            fm.go()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FileMunger(object):\n",
      "    \n",
      "    def __init__(self, sample_curator, target_dir, result_source):\n",
      "        \n",
      "        self.lib = sample_curator.lib\n",
      "        self.dir = target_dir \n",
      "        self.target = target_dir + '_test'\n",
      "        self.rs = result_source\n",
      "        \n",
      "        self.sod = sample_curator.sd[result_source]\n",
      "        self.prep_output_subdir()\n",
      "    \n",
      "    def prep_output_subdir(self):\n",
      "        \n",
      "        source_subdir_dict = {'fastqc': os.path.join(self.lib, 'qcR1'),\n",
      "                              'picard_align': self.lib + '_qc',\n",
      "                              'picard_markdups': self.lib + 'MarkDups',\n",
      "                              'picard_rnaseq': self.lib + '_al',\n",
      "                              'trinity': self.lib}\n",
      "        \n",
      "        if self.rs in source_subdir_dict:\n",
      "            out_subdir = source_subdir_dict[self.rs]\n",
      "        else:\n",
      "            out_subdir = ''\n",
      "            \n",
      "        self.subdir = out_subdir        \n",
      "    \n",
      "    def rename_files(self):\n",
      "        \n",
      "        source_output_dict = self.sod\n",
      "        \n",
      "        result_file_dict = {'fastqc_qc_html': 'fastqc_report.html',\n",
      "                            'fastqc_qc_txt': 'fastqc_data.txt',\n",
      "                            'picard_align_metrics_html': 'Picard_Alignment_Summary_Metrics_html.html',\n",
      "                            'picard_markdups_metrics_html': 'MarkDups_Dupes_Marked_html.html',\n",
      "                            'trinity_fasta': 'Trinity.fasta',\n",
      "                            'tophat_stats_metrics_txt': self.lib + 'ths.txt',\n",
      "                            'picard_rnaseq_metrics_text': 'RNA_Seq_Metrics_html.html',\n",
      "                            'htseq_counts_txt': self.lib + '_count.txt',\n",
      "                            'tophat_alignments_bam': self.lib + '.bam',\n",
      "                            'htseq_metrics_txt': self.lib + 'mm.txt'}\n",
      "        \n",
      "        type_subdir_dict = {'qc': 'QC',\n",
      "                            'metrics': 'metrics',\n",
      "                            'counts': 'counts',\n",
      "                            'alignments': 'alignments',\n",
      "                            'trimmed': 'TrimmedFastqs',\n",
      "                            'trinity': 'Trinity'}\n",
      "        \n",
      "        dirs_to_bundle = []\n",
      "        for o in source_output_dict:\n",
      "            rf = source_output_dict[o]['file']\n",
      "            rt = source_output_dict[o]['type']\n",
      "            \n",
      "            if not re.search('fastq$', o):\n",
      "                out_dir = os.path.join(self.target, type_subdir_dict[rt], self.subdir)\n",
      "                if not os.path.isdir(out_dir):\n",
      "                    os.makedirs(out_dir)\n",
      "                if len(self.subdir):\n",
      "                    dirs_to_bundle.append(out_dir)\n",
      "                \n",
      "                src_file = os.path.join(self.dir, type_subdir_dict[rt], os.path.basename(rf)\n",
      "                shutil.copy(src_file),\n",
      "                            os.path.join(out_dir, result_file_dict[o]))\n",
      "        self.bundle = list(set(dirs_to_bundle))\n",
      "                            \n",
      "    def bundle_files(self):\n",
      "        for d in self.bundle:\n",
      "            shutil.make_archive(d, 'zip', d)\n",
      "            shutil.rmtree(d)\n",
      "    \n",
      "    def go(self):\n",
      "        self.rename_files()\n",
      "        self.bundle_files()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processed_dir = \"/Users/jaeddy/Dropbox/data/projects/briSeqPipeline/GLOBUS_TESTING/Project_P43-12Processed_151013/\"\n",
      "processed_dir = os.path.abspath(processed_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = ResultCurator(processed_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc.curate_outputs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "picard_align_metrics_html in source_dict[None]: True\n",
        "trinity_fasta in source_dict[None]: True\n",
        "picard_markdups_metrics_html in source_dict[None]: True\n",
        "fastqc_qc_txt in source_dict[None]: True\n",
        "fastq in source_dict[None]: True\n",
        "tophat_stats_metrics_txt in source_dict[None]: True\n",
        "fastqc_qc_html in source_dict[None]: True\n",
        "trimmed_fastq in source_dict[None]: True\n",
        "picard_rnaseq_metrics_text in source_dict[None]: True\n",
        "htseq_counts_txt in source_dict[None]: True\n",
        "tophat_alignments_bam in source_dict[None]: True\n",
        "htseq_metrics_txt in source_dict[None]: True\n"
       ]
      },
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: '/Users/jaeddy/Dropbox/data/projects/briSeqPipeline/GLOBUS_TESTING/Project_P43-12Processed_151013/alignments/lib6835_C6VG0ANXX_tophat_alignments.bam'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-65-e19817155ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-52-5aad30540fea>\u001b[0m in \u001b[0;36mcurate_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSampleCurator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganize_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-57-ebb0633c7f38>\u001b[0m in \u001b[0;36morganize_files\u001b[0;34m(self, target_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileMunger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-63-a3f5a1e2c4d1>\u001b[0m in \u001b[0;36mgo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbundle_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-63-a3f5a1e2c4d1>\u001b[0m in \u001b[0;36mrename_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 shutil.copy(os.path.join(self.dir, type_subdir_dict[rt], os.path.basename(rf)),\n\u001b[0;32m---> 63\u001b[0;31m                             os.path.join(out_dir, result_file_dict[o]))\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_to_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jaeddy/anaconda/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jaeddy/anaconda/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSpecialFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`%s` is a named pipe\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/jaeddy/Dropbox/data/projects/briSeqPipeline/GLOBUS_TESTING/Project_P43-12Processed_151013/alignments/lib6835_C6VG0ANXX_tophat_alignments.bam'"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lib = rc.od.keys()[0]\n",
      "lib_output_dict = rc.od[lib]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc = SampleCurator(lib_id=lib, output_dict=lib_output_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "source_dict = sc.build_source_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "picard_align_metrics_html in source_dict[picard_align]: True\n",
        "trinity_fasta in source_dict[trinity]: True\n",
        "picard_markdups_metrics_html in source_dict[picard_markdups]: True\n",
        "fastqc_qc_txt in source_dict[fastqc]: True\n",
        "fastq in source_dict[fastq]: True\n",
        "tophat_stats_metrics_txt in source_dict[tophat]: True\n",
        "fastqc_qc_html in source_dict[fastqc]: True\n",
        "trimmed_fastq in source_dict[trimmed_fastq]: True\n",
        "picard_rnaseq_metrics_text in source_dict[picard_rnaseq]: True\n",
        "htseq_counts_txt in source_dict[htseq]: True\n",
        "tophat_alignments_bam in source_dict[tophat]: True\n",
        "htseq_metrics_txt in source_dict[htseq]: True\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rs = source_dict.keys()[0]\n",
      "source_output_dict = source_dict[rs]\n",
      "source_output_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "{'fastqc_qc_html': {'file': '/~/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/Project_P43-12Processed_151013/QC/lib6835_C6VG0ANXX_fastqc_qc.html',\n",
        "  'type': 'qc'},\n",
        " 'fastqc_qc_txt': {'file': '/~/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/Project_P43-12Processed_151013/QC/lib6835_C6VG0ANXX_fastqc_qc.txt',\n",
        "  'type': 'qc'}}"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm = FileMunger(lib_id=lib, processed_dir=processed_dir, result_source=rs, output_dict=source_output_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}