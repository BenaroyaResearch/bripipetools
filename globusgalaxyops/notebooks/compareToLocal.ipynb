{
 "metadata": {
  "name": "",
  "signature": "sha256:29a08d4ff7c8bbaa4db2012b2996bb58ce3ceeeed2a42f8c3e59dfdbb106a1e4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, re, zipfile, csv\n",
      "from pprint import pprint\n",
      "from bs4 import BeautifulSoup\n",
      "import pysam\n",
      "from Bio import SeqIO\n",
      "import pandas as pd\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MetricsCollector(object):\n",
      "    \n",
      "    def __init__(self, metrics_dir):\n",
      "        \n",
      "        self.dir = metrics_dir\n",
      "    \n",
      "    def get_metrics_list(self):\n",
      "        \n",
      "        self.ml = [ os.path.join(self.dir, f) \\\n",
      "                    for f in os.listdir(self.dir) \\\n",
      "                    if not re.search('^\\.', f)]\n",
      "\n",
      "    \n",
      "    def parse_picard_html(self, html_doc, source='table'):\n",
      "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
      "        table = soup.findAll('table', attrs={'cellpadding': '3'})\n",
      "\n",
      "        metric_dict = {}\n",
      "        \n",
      "        if len(table):\n",
      "            if source == 'table':\n",
      "                for tr in table[0].findAll('tr'):\n",
      "                    for td in tr.findAll('td'):\n",
      "                        if re.search('^([A-Z]+(\\_)*)+$', td.text):\n",
      "                            td_key = td.text.replace('\\n', '')\n",
      "                            td_val = td.next_sibling.string.replace(u'\\xa0', u'')\n",
      "                            td_val = td_val.replace('\\n', '')\n",
      "                            if not re.search('[a-z]', td_val.lower()) and len(td_val):\n",
      "                                td_val = float(td_val)\n",
      "                                metric_dict[td_key] = td_val\n",
      "            elif source == 'cell':             \n",
      "                for tr in table[0].findAll('tr'):\n",
      "                    for td in tr.findAll('td'):\n",
      "                        if re.search('^[A-Z]+', td.text):\n",
      "                            td_keys = td.text.split('\\t')\n",
      "                            td_vals = tr.next_sibling.next_sibling.text.split('\\t')\n",
      "                            td_keys = td_keys[0:len(td_vals)]\n",
      "                            metric_dict = { key: float(td_vals[idx]) for idx,key in enumerate(td_keys) }\n",
      "        else:\n",
      "            print html_doc\n",
      "\n",
      "\n",
      "        return metric_dict\n",
      "\n",
      "    def read_picard(self, metrics_file):\n",
      "        zfile = zipfile.ZipFile(metrics_file)\n",
      "        metric_html = [ f for f in zfile.namelist() if 'html' in f ][0]\n",
      "        if 'rna_seq' in metric_html.lower():\n",
      "            source = 'cell'\n",
      "        else:\n",
      "            source = 'table'\n",
      "\n",
      "        with zfile.open(metric_html) as f:\n",
      "            html_doc = f.read()\n",
      "            metric_dict = self.parse_picard_html(html_doc, source)\n",
      "        return metric_dict\n",
      "\n",
      "    def parse_text(self, metric_lines, source=None):\n",
      "        if source == 'htseq':\n",
      "            metric_dict = { l.split('\\t')[0].lstrip('__'): \\\n",
      "                            float(l.split('\\t')[1].strip()) \\\n",
      "                            for l in metric_lines }\n",
      "\n",
      "        elif source == 'tophat':\n",
      "            metric_dict = { re.sub(' ', '_', l.split('\\t')[1].strip()): \\\n",
      "                            l.split('\\t')[0] \\\n",
      "                            for l in metric_lines }\n",
      "            for m in metric_dict:\n",
      "                val = metric_dict[m]\n",
      "                if type(val) == str and re.search('%', val):\n",
      "                    new_val = float(re.search('[0-9]+(\\.[0-9]+)*', val).group()) / 100\n",
      "                    key = 'perc_' + m\n",
      "                    metric_dict[key] = new_val\n",
      "                    del(metric_dict[m])\n",
      "                else:\n",
      "                    metric_dict[m] = float(val)\n",
      "\n",
      "        return metric_dict\n",
      "\n",
      "    def read_text(self, metrics_file):\n",
      "        if 'mm' in metrics_file:\n",
      "            source = 'htseq'\n",
      "        else:\n",
      "            source = 'tophat'\n",
      "\n",
      "        with open(metrics_file, 'r') as f:\n",
      "            metric_lines = f.readlines()\n",
      "            metric_dict = self.parse_text(metric_lines, source)\n",
      "\n",
      "        return metric_dict\n",
      "    \n",
      "    def build_metric_df(self):\n",
      "        \n",
      "        if not hasattr(self, 'ml'):\n",
      "            self.get_metrics_list()\n",
      "        \n",
      "        lib_metric_dict = {}\n",
      "        for f in self.ml:\n",
      "\n",
      "            if not 'combined' in f:\n",
      "                metrics_file = os.path.join(self.dir, f)\n",
      "\n",
      "                lib = re.search('lib[0-9]+', metrics_file).group()\n",
      "\n",
      "                if 'zip' in metrics_file:\n",
      "                    metrics_dict = self.read_picard(metrics_file)\n",
      "                else:\n",
      "                    metrics_dict = self.read_text(metrics_file)\n",
      "\n",
      "                if lib in lib_metric_dict:\n",
      "                    lib_metric_dict[lib].update(metrics_dict)\n",
      "                else:\n",
      "                    lib_metric_dict[lib] = metrics_dict\n",
      "        \n",
      "        metric_df = pd.DataFrame(lib_metric_dict).transpose()\n",
      "        self.mdf = metric_df\n",
      "        \n",
      "    def write_metric_df(self, out_path):\n",
      "        \n",
      "        if not hasattr(self, 'mdf'):\n",
      "            self.build_metric_df()\n",
      "            \n",
      "        out_path += '_metrics.csv'\n",
      "        \n",
      "        self.mdf.to_csv(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CountsCollector(object):\n",
      "    def __init__(self, counts_dir):\n",
      "                \n",
      "        self.dir = counts_dir\n",
      "    \n",
      "    def get_counts_list(self):\n",
      "        \n",
      "        self.cl = [ os.path.join(self.dir, f) \\\n",
      "                    for f in os.listdir(self.dir) \\\n",
      "                    if not re.search('^\\.', f) ]\n",
      "\n",
      "    def get_lib_id(self, lib_file):\n",
      "        lib_id = re.search('lib[0-9]+(.*(XX)+)*', lib_file).group()\n",
      "\n",
      "        return lib_id\n",
      "\n",
      "    def build_count_dict(self):\n",
      "\n",
      "        if not hasattr(self, 'cl'):\n",
      "            self.get_counts_list()\n",
      "            \n",
      "        count_dict = {}\n",
      "        for idx,f in enumerate(self.cl):\n",
      "            \n",
      "            if not 'combined' in f:\n",
      "                lib = self.get_lib_id(f)\n",
      "                \n",
      "                with open(f) as cf:\n",
      "                    reader = csv.reader(cf, delimiter = '\\t')\n",
      "                    if idx == 0:\n",
      "                        count_header = ['geneName', lib]\n",
      "                        for row in reader:\n",
      "                            count_dict[row[0]] = [row[1]]\n",
      "                    else:\n",
      "                        count_header.append(lib)\n",
      "                        for row in reader:\n",
      "                            count_dict[row[0]].append(row[1])\n",
      "        \n",
      "        self.lcd = count_dict\n",
      "        self.lch = count_header\n",
      "        \n",
      "\n",
      "    def write_count_dict(self, out_path):\n",
      "\n",
      "        if not hasattr(self, 'lcd'):\n",
      "            self.build_count_dict()\n",
      "            \n",
      "        out_path += '_counts.csv'\n",
      "        \n",
      "        with open(out_path, 'w') as cf:\n",
      "            writer = csv.writer(cf)\n",
      "            writer.writerow(self.lch)\n",
      "            for entry in self.lcd:\n",
      "                writer.writerow([entry] + self.lcd[entry])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FileStatsCollector(object):\n",
      "    def __init__(self, proj_dir):\n",
      "                \n",
      "        self.dir = proj_dir\n",
      "    \n",
      "    def get_counts_list(self):\n",
      "        \n",
      "        self.cl = [ os.path.join(self.dir, f) \\\n",
      "                    for f in os.listdir(self.dir) \\\n",
      "                    if not re.search('^\\.', f) ]\n",
      "        \n",
      "    \n",
      "    def get_file_list(self, file_tag):\n",
      "        \n",
      "        file_tag += '$'\n",
      "        file_list = [ os.path.join(dp, f) \\\n",
      "                      for dp,dn,fn in os.walk(self.dir) \\\n",
      "                      for f in fn \\\n",
      "                      if re.search(file_tag, f)]\n",
      "        return file_list\n",
      "    \n",
      "    def get_lib_id(self, lib_file):\n",
      "        lib_id = re.search('lib[0-9]+(.*(XX)+)*', lib_file).group()\n",
      "\n",
      "        return lib_id\n",
      "    \n",
      "    def bufcount(self, filename):\n",
      "        f = open(filename)\n",
      "        lines = 0\n",
      "        buf_size = 1024 * 1024\n",
      "        read_f = f.read # loop optimization\n",
      "\n",
      "        buf = read_f(buf_size)\n",
      "        while buf:\n",
      "            lines += buf.count('\\n')\n",
      "            buf = read_f(buf_size)\n",
      "\n",
      "        return lines\n",
      "    \n",
      "    def get_size(self, filename):\n",
      "        file_size = os.stat(filename).st_size \n",
      "        \n",
      "        return file_size\n",
      "    \n",
      "    def count_bam_records(self, bam_file):\n",
      "        bam_records = list(pysam.AlignmentFile(bam_file, 'rb'))\n",
      "\n",
      "        return len(bam_records)\n",
      "    \n",
      "    def count_fasta_records(self, fasta_file):\n",
      "        handle = open(fasta_file, \"rU\")\n",
      "        fasta_records = list(SeqIO.parse(handle, \"fasta\"))\n",
      "        handle.close()\n",
      "\n",
      "        return len(fasta_records)\n",
      "\n",
      "    def count_fastq_records(self, fastq_file):\n",
      "        handle = open(fastq_file, \"rU\")\n",
      "        fasta_records = list(SeqIO.parse(handle, \"fasta\"))\n",
      "        handle.close()\n",
      "\n",
      "        return len(fasta_records)\n",
      "\n",
      "    def build_file_stat_dict(self):\n",
      "\n",
      "        file_type_list = ['fasta', 'fastq', 'bam']\n",
      "\n",
      "            \n",
      "        file_stat_dict = {}\n",
      "        for ft in file_type_list:\n",
      "            \n",
      "            file_list = self.get_file_list(ft)\n",
      "            for f in file_list:\n",
      "            \n",
      "                if not 'combined' in f:\n",
      "                    lib = self.get_lib_id(f)\n",
      "                    \n",
      "                    if not lib in file_stat_dict:\n",
      "                        file_stat_dict[lib] = {}\n",
      "\n",
      "                    file_stat_dict[lib][ft + '_lines'] = self.bufcount(f)\n",
      "                    file_stat_dict[lib][ft + '_size'] = self.get_size(f)\n",
      "                    \n",
      "                    if ft == 'bam':\n",
      "                        file_stat_dict[lib][ft + '_records'] = self.count_bam_records(f)\n",
      "\n",
      "                    elif ft == 'fasta':\n",
      "                        file_stat_dict[lib][ft + '_records'] = self.count_fasta_records(f)\n",
      "                        \n",
      "                    elif ft == 'fastq':\n",
      "                        file_stat_dict[lib][ft + '_records'] = self.count_fastq_records(f)\n",
      "\n",
      "        \n",
      "        self.fsd = file_stat_dict\n",
      "        \n",
      "\n",
      "    def write_file_stat_dict(self, out_path):\n",
      "\n",
      "        if not hasattr(self, 'fsd'):\n",
      "            self.build_file_stat_dict()\n",
      "            \n",
      "        out_path += '_file_stats.csv'\n",
      "        \n",
      "        pd.DataFrame(self.fsd).transpose().to_csv(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "globus_dir = \"/Volumes/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/gProject_P43-12Processed_151013_formatted/\"\n",
      "local_dir = \"/Volumes/genomics/Illumina/GLOBUS_TESTING_150615_D00565_0087_AC6VG0ANXX/Project_P43-12Processed_151021/\"\n",
      "\n",
      "# globus_dir = \"/Volumes/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/gProject_P109-1Processed_151001_formatted/\"\n",
      "# local_dir = \"/Volumes/genomics/Illumina/GLOBUS_TESTING/Project_P109-1Processed_151021/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collect_project_info(project_dir, out_dir, source):\n",
      "    project = re.search('P[0-9]+\\-[0-9]+', project_dir).group()\n",
      "    \n",
      "    out_tag = project + '_' + source\n",
      "    out_path = os.path.join(out_dir, out_tag)\n",
      "    \n",
      "#     metrics_dir = os.path.join(os.path.abspath(project_dir), 'metrics')\n",
      "#     mc = MetricsCollector(metrics_dir)\n",
      "#     mc.write_metric_df(out_path)\n",
      "    \n",
      "#     counts_dir = os.path.join(os.path.abspath(project_dir), 'counts')\n",
      "#     cc = CountsCollector(counts_dir)\n",
      "#     cc.write_count_dict(out_path)\n",
      "\n",
      "    fsc = FileStatsCollector(project_dir)\n",
      "    fsc.write_file_stat_dict(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_project_info(local_dir, \"../data\", \"local\")\n",
      "# collect_project_info(globus_dir, \"../data\", \"globus\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proj_dir = \"/Volumes/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/gProject_P43-12Processed_151013_formatted/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project = re.search('P[0-9]+\\-[0-9]+', local_dir).group()\n",
      "out_dir = \"../data/\"\n",
      "source = \"local\"\n",
      "out_tag = project + '_' + source\n",
      "out_path = os.path.join(out_dir, out_tag)\n",
      "\n",
      "# fsc.write_file_stat_dict(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsc = FileStatsCollector(local_dir)\n",
      "fsc.build_file_stat_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(fsc.fsd).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>bam_lines</th>\n",
        "      <th>bam_size</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>lib6825_C6VG0ANXX</th>\n",
        "      <td>470657</td>\n",
        "      <td>110974144</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6826_C6VG0ANXX</th>\n",
        "      <td>470106</td>\n",
        "      <td>112019863</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6827_C6VG0ANXX</th>\n",
        "      <td>431633</td>\n",
        "      <td>102329750</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6828_C6VG0ANXX</th>\n",
        "      <td>454959</td>\n",
        "      <td>107851056</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6829_C6VG0ANXX</th>\n",
        "      <td>580928</td>\n",
        "      <td>137696694</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6830_C6VG0ANXX</th>\n",
        "      <td>24850</td>\n",
        "      <td>6019071</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6831_C6VG0ANXX</th>\n",
        "      <td>538690</td>\n",
        "      <td>126391434</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6832_C6VG0ANXX</th>\n",
        "      <td>551447</td>\n",
        "      <td>129841046</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6833_C6VG0ANXX</th>\n",
        "      <td>577266</td>\n",
        "      <td>135483198</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6834_C6VG0ANXX</th>\n",
        "      <td>370102</td>\n",
        "      <td>86722915</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6835_C6VG0ANXX</th>\n",
        "      <td>416677</td>\n",
        "      <td>98175791</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6836_C6VG0ANXX</th>\n",
        "      <td>392114</td>\n",
        "      <td>92999274</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6837_C6VG0ANXX</th>\n",
        "      <td>409109</td>\n",
        "      <td>96969784</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6838_C6VG0ANXX</th>\n",
        "      <td>361544</td>\n",
        "      <td>84941406</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6839_C6VG0ANXX</th>\n",
        "      <td>23549</td>\n",
        "      <td>5617949</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6840_C6VG0ANXX</th>\n",
        "      <td>403457</td>\n",
        "      <td>93785356</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6841_C6VG0ANXX</th>\n",
        "      <td>409904</td>\n",
        "      <td>95580769</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6842_C6VG0ANXX</th>\n",
        "      <td>396283</td>\n",
        "      <td>92853457</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6922_C6VG0ANXX</th>\n",
        "      <td>353420</td>\n",
        "      <td>83367653</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6923_C6VG0ANXX</th>\n",
        "      <td>335966</td>\n",
        "      <td>80291971</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6924_C6VG0ANXX</th>\n",
        "      <td>443877</td>\n",
        "      <td>105241065</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6925_C6VG0ANXX</th>\n",
        "      <td>480454</td>\n",
        "      <td>114992576</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "                   bam_lines   bam_size\n",
        "lib6825_C6VG0ANXX     470657  110974144\n",
        "lib6826_C6VG0ANXX     470106  112019863\n",
        "lib6827_C6VG0ANXX     431633  102329750\n",
        "lib6828_C6VG0ANXX     454959  107851056\n",
        "lib6829_C6VG0ANXX     580928  137696694\n",
        "lib6830_C6VG0ANXX      24850    6019071\n",
        "lib6831_C6VG0ANXX     538690  126391434\n",
        "lib6832_C6VG0ANXX     551447  129841046\n",
        "lib6833_C6VG0ANXX     577266  135483198\n",
        "lib6834_C6VG0ANXX     370102   86722915\n",
        "lib6835_C6VG0ANXX     416677   98175791\n",
        "lib6836_C6VG0ANXX     392114   92999274\n",
        "lib6837_C6VG0ANXX     409109   96969784\n",
        "lib6838_C6VG0ANXX     361544   84941406\n",
        "lib6839_C6VG0ANXX      23549    5617949\n",
        "lib6840_C6VG0ANXX     403457   93785356\n",
        "lib6841_C6VG0ANXX     409904   95580769\n",
        "lib6842_C6VG0ANXX     396283   92853457\n",
        "lib6922_C6VG0ANXX     353420   83367653\n",
        "lib6923_C6VG0ANXX     335966   80291971\n",
        "lib6924_C6VG0ANXX     443877  105241065\n",
        "lib6925_C6VG0ANXX     480454  114992576"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_bam = fsc.get_file_list('bam')[0]\n",
      "test_fasta = fsc.get_file_list('fasta')[0]\n",
      "test_fastq = fsc.get_file_list('fastq')[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_bam_records(bam_file):\n",
      "    bam_records = list(pysam.AlignmentFile(bam_file, 'rb'))\n",
      "\n",
      "    return len(bam_records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "read_alignments(test_bam)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "175577\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_fasta_records(fasta_file):\n",
      "    handle = open(fasta_file, \"rU\")\n",
      "    fasta_records = list(SeqIO.parse(handle, \"fasta\"))\n",
      "    handle.close()\n",
      "    \n",
      "    return = len(fasta_records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(read_fasta(test_fasta))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "2619"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_fastq_records(fastq_file):\n",
      "    handle = open(fastq_file, \"rU\")\n",
      "    fasta_records = list(SeqIO.parse(handle, \"fasta\"))\n",
      "    handle.close()\n",
      "\n",
      "    return len(fasta_records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}