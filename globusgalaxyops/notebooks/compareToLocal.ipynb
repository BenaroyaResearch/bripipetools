{
 "metadata": {
  "name": "",
  "signature": "sha256:40de1311c87b570e6fb904e7e717af1886a0d753dd2822f55eacc36c7c30dcdc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, re, zipfile, csv\n",
      "from pprint import pprint\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MetricsCollector(object):\n",
      "    \n",
      "    def __init__(self, metrics_dir):\n",
      "        \n",
      "        self.dir = metrics_dir\n",
      "    \n",
      "    def get_metrics_list(self):\n",
      "        \n",
      "        self.ml = [ os.path.join(self.dir, f) \\\n",
      "                    for f in os.listdir(self.dir) \\\n",
      "                    if not re.search('^\\.', f)]\n",
      "\n",
      "    \n",
      "    def parse_picard_html(self, html_doc, source='table'):\n",
      "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
      "        table = soup.findAll('table', attrs={'cellpadding': '3'})\n",
      "\n",
      "        metric_dict = {}\n",
      "        \n",
      "        if len(table):\n",
      "            if source == 'table':\n",
      "                for tr in table[0].findAll('tr'):\n",
      "                    for td in tr.findAll('td'):\n",
      "                        if re.search('^([A-Z]+(\\_)*)+$', td.text):\n",
      "                            td_key = td.text.replace('\\n', '')\n",
      "                            td_val = td.next_sibling.string.replace(u'\\xa0', u'')\n",
      "                            td_val = td_val.replace('\\n', '')\n",
      "                            if not re.search('[a-z]', td_val.lower()) and len(td_val):\n",
      "                                td_val = float(td_val)\n",
      "                                metric_dict[td_key] = td_val\n",
      "            elif source == 'cell':             \n",
      "                for tr in table[0].findAll('tr'):\n",
      "                    for td in tr.findAll('td'):\n",
      "                        if re.search('^[A-Z]+', td.text):\n",
      "                            td_keys = td.text.split('\\t')\n",
      "                            td_vals = tr.next_sibling.next_sibling.text.split('\\t')\n",
      "                            td_keys = td_keys[0:len(td_vals)]\n",
      "                            metric_dict = { key: float(td_vals[idx]) for idx,key in enumerate(td_keys) }\n",
      "        else:\n",
      "            print html_doc\n",
      "\n",
      "\n",
      "        return metric_dict\n",
      "\n",
      "    def read_picard(self, metrics_file):\n",
      "        zfile = zipfile.ZipFile(metrics_file)\n",
      "        metric_html = [ f for f in zfile.namelist() if 'html' in f ][0]\n",
      "        if 'rna_seq' in metric_html.lower():\n",
      "            source = 'cell'\n",
      "        else:\n",
      "            source = 'table'\n",
      "\n",
      "        with zfile.open(metric_html) as f:\n",
      "            html_doc = f.read()\n",
      "            metric_dict = self.parse_picard_html(html_doc, source)\n",
      "        return metric_dict\n",
      "\n",
      "    def parse_text(self, metric_lines, source=None):\n",
      "        if source == 'htseq':\n",
      "            metric_dict = { l.split('\\t')[0].lstrip('__'): \\\n",
      "                            float(l.split('\\t')[1].strip()) \\\n",
      "                            for l in metric_lines }\n",
      "\n",
      "        elif source == 'tophat':\n",
      "            metric_dict = { re.sub(' ', '_', l.split('\\t')[1].strip()): \\\n",
      "                            l.split('\\t')[0] \\\n",
      "                            for l in metric_lines }\n",
      "            for m in metric_dict:\n",
      "                val = metric_dict[m]\n",
      "                if type(val) == str and re.search('%', val):\n",
      "                    new_val = float(re.search('[0-9]+(\\.[0-9]+)*', val).group()) / 100\n",
      "                    key = 'perc_' + m\n",
      "                    metric_dict[key] = new_val\n",
      "                    del(metric_dict[m])\n",
      "                else:\n",
      "                    metric_dict[m] = float(val)\n",
      "\n",
      "        return metric_dict\n",
      "\n",
      "    def read_text(self, metrics_file):\n",
      "        if 'mm' in metrics_file:\n",
      "            source = 'htseq'\n",
      "        else:\n",
      "            source = 'tophat'\n",
      "\n",
      "        with open(metrics_file, 'r') as f:\n",
      "            metric_lines = f.readlines()\n",
      "            metric_dict = self.parse_text(metric_lines, source)\n",
      "\n",
      "        return metric_dict\n",
      "    \n",
      "    def build_metric_df(self):\n",
      "        \n",
      "        if not hasattr(self, 'ml'):\n",
      "            self.get_metrics_list()\n",
      "        \n",
      "        lib_metric_dict = {}\n",
      "        for f in self.ml:\n",
      "\n",
      "            if not 'combined' in f:\n",
      "                metrics_file = os.path.join(self.dir, f)\n",
      "\n",
      "                lib = re.search('lib[0-9]+', metrics_file).group()\n",
      "\n",
      "                if 'zip' in metrics_file:\n",
      "                    metrics_dict = self.read_picard(metrics_file)\n",
      "                else:\n",
      "                    metrics_dict = self.read_text(metrics_file)\n",
      "\n",
      "                if lib in lib_metric_dict:\n",
      "                    lib_metric_dict[lib].update(metrics_dict)\n",
      "                else:\n",
      "                    lib_metric_dict[lib] = metrics_dict\n",
      "        \n",
      "        metric_df = pd.DataFrame(lib_metric_dict).transpose()\n",
      "        self.mdf = metric_df\n",
      "        \n",
      "    def write_metric_df(self, out_path):\n",
      "        \n",
      "        if not hasattr(self, 'mdf'):\n",
      "            self.build_metric_df()\n",
      "            \n",
      "        out_path += '_metrics.csv'\n",
      "        \n",
      "        self.mdf.to_csv(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CountsCollector(object):\n",
      "    def __init__(self, counts_dir):\n",
      "                \n",
      "        self.dir = counts_dir\n",
      "    \n",
      "    def get_counts_list(self):\n",
      "        \n",
      "        self.cl = [ os.path.join(self.dir, f) \\\n",
      "                    for f in os.listdir(self.dir) \\\n",
      "                    if not re.search('^\\.', f) ]\n",
      "\n",
      "    def get_lib_id(self, lib_file):\n",
      "        lib_id = re.search('lib[0-9]+(.*(XX)+)*', lib_file).group()\n",
      "\n",
      "        return lib_id\n",
      "\n",
      "    def build_count_dict(self):\n",
      "\n",
      "        if not hasattr(self, 'cl'):\n",
      "            self.get_counts_list()\n",
      "            \n",
      "        count_dict = {}\n",
      "        for idx,f in enumerate(self.cl):\n",
      "            \n",
      "            if not 'combined' in f:\n",
      "                lib = self.get_lib_id(f)\n",
      "                \n",
      "                with open(f) as cf:\n",
      "                    reader = csv.reader(cf, delimiter = '\\t')\n",
      "                    if idx == 0:\n",
      "                        count_header = ['geneName', lib]\n",
      "                        for row in reader:\n",
      "                            count_dict[row[0]] = [row[1]]\n",
      "                    else:\n",
      "                        count_header.append(lib)\n",
      "                        for row in reader:\n",
      "                            count_dict[row[0]].append(row[1])\n",
      "        \n",
      "        self.lcd = count_dict\n",
      "        self.lch = count_header\n",
      "        \n",
      "\n",
      "    def write_count_dict(self, out_path):\n",
      "\n",
      "        if not hasattr(self, 'lcd'):\n",
      "            self.build_count_dict()\n",
      "            \n",
      "        out_path += '_counts.csv'\n",
      "        \n",
      "        with open(out_path, 'w') as cf:\n",
      "            writer = csv.writer(cf)\n",
      "            writer.writerow(self.lch)\n",
      "            for entry in self.lcd:\n",
      "                writer.writerow([entry] + self.lcd[entry])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FileStatsCollector(object):\n",
      "    def __init__(self, proj_dir):\n",
      "                \n",
      "        self.dir = proj_dir\n",
      "    \n",
      "    def get_counts_list(self):\n",
      "        \n",
      "        self.cl = [ os.path.join(self.dir, f) \\\n",
      "                    for f in os.listdir(self.dir) \\\n",
      "                    if not re.search('^\\.', f) ]\n",
      "        \n",
      "    \n",
      "    def get_file_list(self, file_tag):\n",
      "        \n",
      "        file_list = [ os.path.join(dp, f) \\\n",
      "                      for dp,dn,fn in os.walk(self.dir) \\\n",
      "                      for f in fn \\\n",
      "                      if re.search(file_tag, f)]\n",
      "        return file_list\n",
      "    \n",
      "    def get_lib_id(self, lib_file):\n",
      "        lib_id = re.search('lib[0-9]+(.*(XX)+)*', lib_file).group()\n",
      "\n",
      "        return lib_id\n",
      "    \n",
      "    def bufcount(self, filename):\n",
      "        f = open(filename)\n",
      "        lines = 0\n",
      "        buf_size = 1024 * 1024\n",
      "        read_f = f.read # loop optimization\n",
      "\n",
      "        buf = read_f(buf_size)\n",
      "        while buf:\n",
      "            lines += buf.count('\\n')\n",
      "            buf = read_f(buf_size)\n",
      "\n",
      "        return lines\n",
      "    \n",
      "    def get_size(self, filename):\n",
      "        file_size = os.stat(filename).st_size \n",
      "        \n",
      "        return file_size\n",
      "\n",
      "\n",
      "    def build_file_stat_dict(self):\n",
      "\n",
      "        file_type_list = ['fasta', 'fastq', 'bam']\n",
      "\n",
      "            \n",
      "        file_stat_dict = {}\n",
      "        for ft in file_type_list:\n",
      "            \n",
      "            file_list = self.get_file_list(ft)\n",
      "            for f in file_list:\n",
      "            \n",
      "                if not 'combined' in f:\n",
      "                    lib = self.get_lib_id(f)\n",
      "                    \n",
      "                    if not lib in file_stat_dict:\n",
      "                        file_stat_dict[lib] = {}\n",
      "\n",
      "                    file_stat_dict[lib][ft + '_lines'] = self.bufcount(f)\n",
      "                    file_stat_dict[lib][ft + '_size'] = self.get_size(f)\n",
      "        \n",
      "        self.fsd = file_stat_dict\n",
      "        \n",
      "\n",
      "    def write_file_stat_dict(self, out_path):\n",
      "\n",
      "        if not hasattr(self, 'fsd'):\n",
      "            self.build_file_stat_dict()\n",
      "            \n",
      "        out_path += '_file_stats.csv'\n",
      "        \n",
      "        pd.DataFrame(self.fsd).transpose().to_csv(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "globus_dir = \"/Volumes/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/gProject_P43-12Processed_151013_formatted/\"\n",
      "local_dir = \"/Volumes/genomics/Illumina/GLOBUS_TESTING_150615_D00565_0087_AC6VG0ANXX/Project_P43-12Processed_151021/\"\n",
      "\n",
      "# globus_dir = \"/Volumes/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/gProject_P109-1Processed_151001_formatted/\"\n",
      "# local_dir = \"/Volumes/genomics/Illumina/GLOBUS_TESTING/Project_P109-1Processed_151021/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collect_project_info(project_dir, out_dir, source):\n",
      "    project = re.search('P[0-9]+\\-[0-9]+', project_dir).group()\n",
      "    \n",
      "    out_tag = project + '_' + source\n",
      "    out_path = os.path.join(out_dir, out_tag)\n",
      "    \n",
      "#     metrics_dir = os.path.join(os.path.abspath(project_dir), 'metrics')\n",
      "#     mc = MetricsCollector(metrics_dir)\n",
      "#     mc.write_metric_df(out_path)\n",
      "    \n",
      "#     counts_dir = os.path.join(os.path.abspath(project_dir), 'counts')\n",
      "#     cc = CountsCollector(counts_dir)\n",
      "#     cc.write_count_dict(out_path)\n",
      "\n",
      "    fsc = FileStatsCollector(project_dir)\n",
      "    fsc.write_file_stat_dict(out_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_project_info(local_dir, \"../data\", \"local\")\n",
      "# collect_project_info(globus_dir, \"../data\", \"globus\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proj_dir = \"/Volumes/genomics/Illumina/150615_D00565_0087_AC6VG0ANXX/gProject_P43-12Processed_151013_formatted/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_file_list(proj_dir, file_tag):\n",
      "    file_list = [ os.path.join(dp, f) \\\n",
      "                  for dp,dn,fn in os.walk(proj_dir) \\\n",
      "                  for f in fn \\\n",
      "                  if re.search(file_tag, f)]\n",
      "    return file_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsc = FileStatsCollector(proj_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsc.build_file_stat_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsc.fsd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "{'lib6825_C6VG0ANXX': {'fasta_lines': 20765, 'fasta_size': 1236147},\n",
        " 'lib6826_C6VG0ANXX': {'fasta_lines': 16842, 'fasta_size': 1001037},\n",
        " 'lib6827_C6VG0ANXX': {'fasta_lines': 23992, 'fasta_size': 1423927},\n",
        " 'lib6828_C6VG0ANXX': {'fasta_lines': 23386, 'fasta_size': 1391223},\n",
        " 'lib6829_C6VG0ANXX': {'fasta_lines': 32737, 'fasta_size': 1939219},\n",
        " 'lib6830_C6VG0ANXX': {'fasta_lines': 766, 'fasta_size': 45042},\n",
        " 'lib6831_C6VG0ANXX': {'fasta_lines': 20261, 'fasta_size': 1196446},\n",
        " 'lib6832_C6VG0ANXX': {'fasta_lines': 19739, 'fasta_size': 1172699},\n",
        " 'lib6833_C6VG0ANXX': {'fasta_lines': 27300, 'fasta_size': 1631967},\n",
        " 'lib6834_C6VG0ANXX': {'fasta_lines': 15601, 'fasta_size': 935185},\n",
        " 'lib6835_C6VG0ANXX': {'fasta_lines': 19182, 'fasta_size': 1136701},\n",
        " 'lib6836_C6VG0ANXX': {'fasta_lines': 20631, 'fasta_size': 1225168},\n",
        " 'lib6837_C6VG0ANXX': {'fasta_lines': 19284, 'fasta_size': 1142600},\n",
        " 'lib6838_C6VG0ANXX': {'fasta_lines': 14385, 'fasta_size': 861719},\n",
        " 'lib6839_C6VG0ANXX': {'fasta_lines': 733, 'fasta_size': 44684},\n",
        " 'lib6840_C6VG0ANXX': {'fasta_lines': 13021, 'fasta_size': 776543},\n",
        " 'lib6841_C6VG0ANXX': {'fasta_lines': 11955, 'fasta_size': 714992},\n",
        " 'lib6842_C6VG0ANXX': {'fasta_lines': 16076, 'fasta_size': 959324},\n",
        " 'lib6922_C6VG0ANXX': {'fasta_lines': 19606, 'fasta_size': 1160911},\n",
        " 'lib6923_C6VG0ANXX': {'fasta_lines': 24302, 'fasta_size': 1435901},\n",
        " 'lib6924_C6VG0ANXX': {'fasta_lines': 27902, 'fasta_size': 1651124},\n",
        " 'lib6925_C6VG0ANXX': {'fasta_lines': 42669, 'fasta_size': 2525094}}"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(fsc.fsd).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>fasta_lines</th>\n",
        "      <th>fasta_size</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>lib6825_C6VG0ANXX</th>\n",
        "      <td>20765</td>\n",
        "      <td>1236147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6826_C6VG0ANXX</th>\n",
        "      <td>16842</td>\n",
        "      <td>1001037</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6827_C6VG0ANXX</th>\n",
        "      <td>23992</td>\n",
        "      <td>1423927</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6828_C6VG0ANXX</th>\n",
        "      <td>23386</td>\n",
        "      <td>1391223</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6829_C6VG0ANXX</th>\n",
        "      <td>32737</td>\n",
        "      <td>1939219</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6830_C6VG0ANXX</th>\n",
        "      <td>766</td>\n",
        "      <td>45042</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6831_C6VG0ANXX</th>\n",
        "      <td>20261</td>\n",
        "      <td>1196446</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6832_C6VG0ANXX</th>\n",
        "      <td>19739</td>\n",
        "      <td>1172699</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6833_C6VG0ANXX</th>\n",
        "      <td>27300</td>\n",
        "      <td>1631967</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6834_C6VG0ANXX</th>\n",
        "      <td>15601</td>\n",
        "      <td>935185</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6835_C6VG0ANXX</th>\n",
        "      <td>19182</td>\n",
        "      <td>1136701</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6836_C6VG0ANXX</th>\n",
        "      <td>20631</td>\n",
        "      <td>1225168</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6837_C6VG0ANXX</th>\n",
        "      <td>19284</td>\n",
        "      <td>1142600</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6838_C6VG0ANXX</th>\n",
        "      <td>14385</td>\n",
        "      <td>861719</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6839_C6VG0ANXX</th>\n",
        "      <td>733</td>\n",
        "      <td>44684</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6840_C6VG0ANXX</th>\n",
        "      <td>13021</td>\n",
        "      <td>776543</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6841_C6VG0ANXX</th>\n",
        "      <td>11955</td>\n",
        "      <td>714992</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6842_C6VG0ANXX</th>\n",
        "      <td>16076</td>\n",
        "      <td>959324</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6922_C6VG0ANXX</th>\n",
        "      <td>19606</td>\n",
        "      <td>1160911</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6923_C6VG0ANXX</th>\n",
        "      <td>24302</td>\n",
        "      <td>1435901</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6924_C6VG0ANXX</th>\n",
        "      <td>27902</td>\n",
        "      <td>1651124</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lib6925_C6VG0ANXX</th>\n",
        "      <td>42669</td>\n",
        "      <td>2525094</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "                   fasta_lines  fasta_size\n",
        "lib6825_C6VG0ANXX        20765     1236147\n",
        "lib6826_C6VG0ANXX        16842     1001037\n",
        "lib6827_C6VG0ANXX        23992     1423927\n",
        "lib6828_C6VG0ANXX        23386     1391223\n",
        "lib6829_C6VG0ANXX        32737     1939219\n",
        "lib6830_C6VG0ANXX          766       45042\n",
        "lib6831_C6VG0ANXX        20261     1196446\n",
        "lib6832_C6VG0ANXX        19739     1172699\n",
        "lib6833_C6VG0ANXX        27300     1631967\n",
        "lib6834_C6VG0ANXX        15601      935185\n",
        "lib6835_C6VG0ANXX        19182     1136701\n",
        "lib6836_C6VG0ANXX        20631     1225168\n",
        "lib6837_C6VG0ANXX        19284     1142600\n",
        "lib6838_C6VG0ANXX        14385      861719\n",
        "lib6839_C6VG0ANXX          733       44684\n",
        "lib6840_C6VG0ANXX        13021      776543\n",
        "lib6841_C6VG0ANXX        11955      714992\n",
        "lib6842_C6VG0ANXX        16076      959324\n",
        "lib6922_C6VG0ANXX        19606     1160911\n",
        "lib6923_C6VG0ANXX        24302     1435901\n",
        "lib6924_C6VG0ANXX        27902     1651124\n",
        "lib6925_C6VG0ANXX        42669     2525094"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}