{
 "metadata": {
  "name": "",
  "signature": "sha256:d80dc0d47ea4e43d765eb7c6f20b51cbfec1bfc14221b89e7de4827d16716441"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, re, sys\n",
      "from pymongo import MongoClient\n",
      "from pprint import pprint\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client = MongoClient()\n",
      "db = client.tg3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# wrapper function for regex matching\n",
      "def match_or_empty(string, pattern):\n",
      "    regex = re.compile(pattern)\n",
      "    match = regex.search(string)\n",
      "    if match is not None:\n",
      "        return match.group()\n",
      "    else:\n",
      "        return ''\n",
      "\n",
      "### file/path/string parsing functions ###\n",
      "\n",
      "def get_lib_id(lib_str):\n",
      "    lib_id = match_or_empty(lib_str, 'lib[1-9]+[0-9]*')\n",
      "    \n",
      "    return lib_id\n",
      "\n",
      "def parse_fc_str(fc_str):\n",
      "    fc_parts = fc_str.split('_')\n",
      "\n",
      "    d = datetime.datetime.strptime(fc_parts[0], '%y%m%d')\n",
      "    date = datetime.date.isoformat(d)\n",
      "    instrument_id = fc_parts[1]\n",
      "    run_id = int(fc_parts[2])\n",
      "    \n",
      "    fc_id = match_or_empty(fc_str, '(?<=(_(A|B|D)))([A-Z]|[0-9])*XX')\n",
      "\n",
      "    return date, instrument_id, run_id, fc_id\n",
      "    \n",
      "    \n",
      "def get_proj_id(proj_str):\n",
      "    proj = match_or_empty(proj_str, 'P+[0-9]+(-[0-9]+){,1}')\n",
      "    proj_id = int(match_or_empty(proj, '(?<=P)[0-9]+'))\n",
      "    subproj_id = int(match_or_empty(proj, '(?<=-)[0-9]+'))\n",
      "    \n",
      "    return proj_id, subproj_id\n",
      "\n",
      "def parse_lib_list_entry(line):\n",
      "    l_parts = line.strip().split('\\t')\n",
      "    \n",
      "    lib_id = get_lib_id(l_parts[0])\n",
      "    flowcell_str = l_parts[2]\n",
      "    project_id,subproject_id = get_proj_id(l_parts[3])\n",
      "    file_path = l_parts[-1]\n",
      "    \n",
      "    return lib_id, flowcell_str, project_id, subproject_id, file_path\n",
      "\n",
      "### file parsing/annotating functions ###\n",
      "\n",
      "def get_file_type(file_path):\n",
      "    ext = os.path.splitext(file_path)\n",
      "    if 'z' in ext[-1]:\n",
      "        compression = ext[-1].lstrip('.')\n",
      "        ext = os.path.splitext(ext[0])[-1].lstrip('.')\n",
      "    return ext, compression\n",
      "\n",
      "def get_fastq_source(file_path):\n",
      "    lane_id = int(match_or_empty(file_path, '(?<=L00)[1-8]'))\n",
      "    read_id = int(match_or_empty(file_path, '(?<=R)[1-2]'))\n",
      "    return lane_id, read_id\n",
      "    \n",
      "def collect_file_info(file_path):\n",
      "    file_type,compression = get_file_type(file_path)\n",
      "    \n",
      "    if file_type == 'fastq':\n",
      "        lane_id,read_id = get_fastq_source(file_path)\n",
      "    \n",
      "    file_path = re.sub('.*(?=/genomics)', '', file_path)\n",
      "    \n",
      "    file_dict = {'path': file_path, 'type': file_type, 'compression': compression,\n",
      "                 'lane_id': lane_id, 'read_id': read_id}\n",
      "    return(file_dict)\n",
      "\n",
      "\n",
      "# describe raw files for current lib\n",
      "def list_lib_raw_files(file_dir):\n",
      "    if not os.path.isdir(file_dir):\n",
      "        file_dir = re.sub('mnt', 'Volumes', file_dir)\n",
      "        \n",
      "    file_list = [ collect_file_info(os.path.join(file_dir, f)) \\\n",
      "                  for f in os.listdir(file_dir) ]\n",
      "    return file_list\n",
      "\n",
      "# read and extract info from library list file\n",
      "def read_lib_list(lib_list_file):\n",
      "    with open(lib_list_file) as f:\n",
      "        lib_list_lines = f.readlines()\n",
      "\n",
      "        lib_dict = {}\n",
      "        fc_dict = {}\n",
      "        for l in lib_list_lines[1:]:\n",
      "            lib_id,fc_str,proj_id,subproj_id,file_path = parse_lib_list_entry(l)\n",
      "            fc_date,instr,run_id,fc_id = parse_fc_str(fc_str)\n",
      "            raw_file_list = list_lib_raw_files(file_dir)\n",
      "\n",
      "            if fc_id not in fc_dict:\n",
      "                fc_dict[fc_id] = \\\n",
      "                    {'date': fc_date,\n",
      "                     'type': 'flowcell',\n",
      "                     'instrument_id': instr,\n",
      "                     'run_id': run_id,\n",
      "                     'lanes': [ {'lane_id': l,\n",
      "                                 'libraries': []} for l in range(1, 9) ]}\n",
      "                    \n",
      "            lib_lanes = [ f.get('lane_id') for f in raw_files ]\n",
      "            [ fc_dict[fc_id]['lanes'][idx]['libraries'].append({'lib_id': lib_id}) \\\n",
      "              for idx,l in enumerate(fc_dict[fc_id]['lanes']) \\\n",
      "              if l.get('lane_id') in lib_lanes ]\n",
      "                \n",
      "            if lib_id not in lib_dict:\n",
      "                lib_dict[lib_id] = \\\n",
      "                    {'assays': \n",
      "                         [{'assay_id': fc_id,\n",
      "                           'raw_data': raw_file_list}], \n",
      "                     'project_id': proj_id,\n",
      "                     'subproject_id': subproj_id}\n",
      "            else:\n",
      "                lib_fastq_dict[lib_id]['assays'].append({'assay_id': flowcell_id})\n",
      "    \n",
      "    return fc_dict, lib_dict\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lib_list_file = \"../data/lib_list_151216_P85.txt\"\n",
      "fc_dict,lib_dict = read_lib_list(lib_list_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pprint(fc_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'C81A1ANXX': {'date': '2015-12-16',\n",
        "               'instrument_id': 'D00565',\n",
        "               'lanes': [{'lane_id': 1, 'libraries': []},\n",
        "                         {'lane_id': 2, 'libraries': []},\n",
        "                         {'lane_id': 3, 'libraries': []},\n",
        "                         {'lane_id': 4, 'libraries': []},\n",
        "                         {'lane_id': 5, 'libraries': []},\n",
        "                         {'lane_id': 6, 'libraries': []},\n",
        "                         {'lane_id': 7,\n",
        "                          'libraries': [{'lib_id': 'lib10181'},\n",
        "                                        {'lib_id': 'lib10183'},\n",
        "                                        {'lib_id': 'lib10180'}]},\n",
        "                         {'lane_id': 8, 'libraries': []}],\n",
        "               'run_id': 100,\n",
        "               'type': 'flowcell'}}\n"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_files = list_lib_raw_files(file_dir)\n",
      "raw_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "[{'compression': 'gz',\n",
        "  'lane_id': 7,\n",
        "  'path': '/genomics/Illumina/151216_D00565_0100_AC81A1ANXX/Unaligned/P85-9-27316300/lib10180-31653713/CD4plusCCR5plusGFPplusBlood_S246_L007_R1_001.fastq.gz',\n",
        "  'read_id': 1,\n",
        "  'type': 'fastq'}]"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ f.get('lane_id') for f in raw_files ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 212,
       "text": [
        "[7]"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def to_camel_case(snake_str):\n",
      "    components = snake_str.split('_')\n",
      "    return components[0] + \"\".join(x.title() for x in components[1:])\n",
      "\n",
      "def convert_dict_keys(obj):\n",
      "    if isinstance(obj, list):\n",
      "        new_obj = [ convert_dict_keys(i) for i in obj ]\n",
      "    elif isinstance(obj, dict):\n",
      "        new_obj = { to_camel_case(k): convert_dict_keys(obj[k]) \\\n",
      "                    for k in obj }\n",
      "    else:\n",
      "        new_obj = obj\n",
      "    return new_obj\n",
      "\n",
      "def merge_two_dicts(x, y):\n",
      "    '''Given two dicts, merge them into a new dict as a shallow copy.'''\n",
      "    z = x.copy()\n",
      "    z.update(y)\n",
      "    return z\n",
      "\n",
      "def lib_dict_to_db(lib_dict):\n",
      "    lib_db = [ merge_two_dicts({'_id': i}, convert_dict_keys(lib_dict[i])) \\\n",
      "               for i in lib_dict ]\n",
      "    return lib_db\n",
      "\n",
      "def fc_dict_to_db(fc_dict):\n",
      "    fc_db = [ merge_two_dicts({'_id': i}, convert_dict_keys(fc_dict[i])) \\\n",
      "              for i in fc_dict ]\n",
      "    return fc_db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lib_dict_to_db(lib_dict)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "{'_id': 'lib10204',\n",
        " 'assays': [{'assayId': 'C81A1ANXX',\n",
        "   'rawData': [{'compression': 'gz',\n",
        "     'laneId': 7,\n",
        "     'path': '/genomics/Illumina/151216_D00565_0100_AC81A1ANXX/Unaligned/P85-9-27316300/lib10180-31653713/CD4plusCCR5plusGFPplusBlood_S246_L007_R1_001.fastq.gz',\n",
        "     'readId': 1,\n",
        "     'type': 'fastq'}]}],\n",
        " 'projectId': 43,\n",
        " 'subprojectId': 36}"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fc_dict_to_db(fc_dict)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 185,
       "text": [
        "{'_id': 'C81A1ANXX',\n",
        " 'date': '2015-12-16',\n",
        " 'instrumentId': 'D00565',\n",
        " 'runId': 100,\n",
        " 'type': 'flowcell'}"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ {'lane_id': l} for l in range(1, 9) ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 201,
       "text": [
        "[{'lane_id': 1},\n",
        " {'lane_id': 2},\n",
        " {'lane_id': 3},\n",
        " {'lane_id': 4},\n",
        " {'lane_id': 5},\n",
        " {'lane_id': 6},\n",
        " {'lane_id': 7},\n",
        " {'lane_id': 8}]"
       ]
      }
     ],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}