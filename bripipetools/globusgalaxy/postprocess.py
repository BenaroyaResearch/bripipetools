import os

from bripipetools.util import strings
from bripipetools.io import labels
from bripipetools.io.parsers import WorkflowParser

class ProcessedBatch(object):
    def __init__(self, batch_submit_file, flowcell_dir=None):
        """
        Representation of and operations for the set of outputs generated by
        a batch processing job in Globus Galaxy.

        :type batch_submit_file: str
        :param batch_submit_file: File path of the batch submit file.

        :type flowcell_dir: str
        :param flowcell_dir: Path to flowcell folder where outputs are to be
            stored; if not specified, assumed to be one level up from folder
            containing ``batch_submit_file``.
        """
        self.submit_file = batch_submit_file
        if flowcell_dir is None:
            self.fc_dir = os.path.dirname(os.path.dirname(self.submit_file))
        else:
            self.fc_dir = flowcell_dir

    def _match_sample_project(self, sample_output_map, sample):
        """
        For a selected sample, check the location of the workflow log output
        file to determine the correct project folder.

        :type sample_output_map: dict
        :param sample_output_map: Dict mapping samples to expected output
            files in the flowcell folder.

        :type sample: str
        :param sample: Name of current sample (i.e., a key in the
            sample-to-output mapping dictionary)

        :rtype: str
        :return: File path of project folder for the current sample.
        """
        log_file = sample_output_map[sample].get('workflow_log_txt')
        project_folder = strings.matchdefault('Project_[^/]*', log_file)
        return os.path.join(self.fc_dir, project_folder)

    def curate_outputs(self):
        """
        For each sample in the processed batch, identify and classify each
        output file present in the flowcell folder; rename and reorganize files
        as needed.
        """
        wp = WorkflowParser(self.submit_file)
        workflow_name = wp.get_workflow_name()
        sample_output_map = wp.get_batch_outputs()

        for idx, sample in enumerate(sample_output_map):
            project_dir = self._match_sample_project(sample_output_map, sample)
            project_id, subproject_id = labels.get_proj_id(project_dir)
            print('\nWorkflow: {}'.format(workflow_name))
            print('>> Compiling ouputs for {} [P{}-{}] ({} of {})\n'
                  .format(sample, project_id, subproject_id,
                          idx + 1, len(sample_output_map)))
            # sc = SampleCurator(sample_output_map, sample)
            # sc.organize_files(project_dir)

class SampleCurator(object):
    # TODO: this might make sense as a separate module for annotating outputs,
    # might overlap with similar tasks for Galaxy Datasets
    def __init__(self, sample_output_map, sample):
        """
        Methods for annotating / classifying output files for a selected sample.

        :type sample_output_map: dict
        :param sample_output_map: Dict mapping samples to expected output
            files in the flowcell folder.

        :type sample: str
        :param sample: Name of current sample (i.e., a key in the
            sample-to-output mapping dictionary)
        """
        self.output_map = sample_output_map[sample]
        self.sample = sample

    def _get_output_type(self, output):
        output_str = re.sub('_[a-z]+$', '', output)
        return strings.matchdefault('(?<=_)[a-z]+$', output_str,
                                    output_str)


    def _get_output_source(self, output):
        if not re.search('fastq$', output):
            output_sources = ['picard_align', 'picard_markdups', 'picard_rnaseq',
                              'htseq', 'trinity', 'tophat', 'tophat_stats', 'fastqc',
                              'workflow_log']
            return [s for s in output_sources
                    if re.search(s.lower(), output)][0]
        else:
            output_sources = ['fastq', 'trimmed_fastq']
            return [s for s in output_sources
                    if re.search('^' + s.lower() + '$', output)][0]

    def get_source_outputs(self):
        source_output_map = {}
        for o in self.output_map:
            rt = self._get_output_type(o)
            rs = self._get_output_source(o)

            source_ouput_map.setdefault(rs, {})[o] = {'file': output_dict[o],
                                                      'type': rt}

            # if rs in source_dict:
            #     source_output_map[rs][o] = {'file': output_dict[o],
            #                           'type': rt}
            # else:
            #     source_dict[rs] = {o: {'file': output_dict[o],
            #                            'type': rt}}

        self.source_outputs = source_output_map

    def organize_files(self, target_dir):

        if not hasattr(self, 'source_outputs'):
            self.get_source_outputs()

        for s in self.source_outputs:
            fm = FileMunger(self, target_dir, s)
            fm.go()
