"""
Identify, classify, format, and organize outputs from a Globus Galaxy batch
processing job.
"""

import os
import re

from bripipetools.util import strings
from bripipetools.util import files
from bripipetools.io.parsers import WorkflowParser


class BatchCurator(object):
    def __init__(self, batch_submit_file, flowcell_dir=None):
        """
        Controls operations (identification, annotation, etc.) for the set of
        outputs generated by a batch processing job in Globus Galaxy.

        :type batch_submit_file: str
        :param batch_submit_file: File path of the batch submit file.

        :type flowcell_dir: str
        :param flowcell_dir: Path to flowcell folder where outputs are to be
            stored; if not specified, assumed to be one level up from folder
            containing ``batch_submit_file``.
        """
        self.submit_file = batch_submit_file
        if flowcell_dir is None:
            self.fc_dir = os.path.dirname(os.path.dirname(self.submit_file))
        else:
            self.fc_dir = flowcell_dir
        self._load_output_map()
        self._clean_output_paths()

    def _load_output_map(self):
        """
        Parse the batch submit file to obtain and store the mapping between
        samples and their expected output files.
        """
        wp = WorkflowParser(self.submit_file)
        self.workflow_name = wp.get_workflow_name()
        self.sample_output_map = wp.get_batch_outputs()

    def _clean_output_paths(self):
        """
        Replaces ambigious file path roots with current system root.
        """
        sample_output_map = self.sample_output_map
        current_root = files.locate_root_folder('genomics')

        for (sample, sample_files) in sample_output_map.items():
            for file_id in sample_files:
                sample_files[file_id] = files.swap_root(sample_files[file_id],
                                                        'genomics',
                                                        current_root)

        self.sample_output_map = sample_output_map

    def _match_sample_project(self, sample):
        """
        For a selected sample, check the location of the workflow log output
        file to determine the correct project folder.

        :type sample: str
        :param sample: Name of current sample (i.e., a key in the
            sample-to-output mapping dictionary)

        :rtype: str
        :return: File path of project folder for the current sample.
        """
        sample_output_map = self.sample_output_map

        log_file = sample_output_map[sample].get('workflow_log_txt')
        project_folder = strings.matchdefault('Project_[^/]*', log_file)
        return os.path.join(self.fc_dir, project_folder)

    def _fix_globus_dir(self, project_dir):
        """
        If not already in the target folder path, insert the 'globus' tag to
        avoid overwriting data from local processing jobs.

        :type project_dir: str
        :param target_dir: Path to folder where processed data is stored for
            a project.

        :rtype: str
        :return: File path with 'globus' tag inserted after 'Processed'
        """

        if not re.search('_globus_', project_dir):
            return re.sub('Processed_', 'Processed_globus_', project_dir)
        else:
            return project_dir

    def check_outputs(self):
        """
        Check whether all expected output files are present for each sample in
        the batch.

        :rtype: dict
        :return: A dict, where for each ``sample``, output files are flagged as
            ok, missing, or empty.
        """
        sample_output_map = self.sample_output_map

        output_status_dict = {}
        for sample in sample_output_map:
            output_list = [{'path': v, 'type': k}
                           for (k, v) in sample_output_map[sample].items()]

            for f in output_list:
                f['exists'] = os.path.exists(f['path'])
                f['size'] = os.stat(f['path']).st_size if f['exists'] else 0
                if not f['exists']:
                    f['status'] = 'missing'
                else:
                    f['status'] = 'empty' if f['size'] == 0 else 'ok'
            output_status_dict[sample] = output_list

        return output_status_dict

    def report_problem_outputs(self):
        """
        Return non-zero status and display missing/empty files (if any exist).
        """
        # TODO: turn this into an actual error message / raise exception
        output_status_dict = self.check_outputs()

        problem_outputs = [(sample, output['path'])
                           for sample in output_status_dict
                           for output in output_status_dict[sample]
                           if output['status'] != 'ok']

        if len(problem_outputs):
            return problem_outputs

