import os

from bripipetools.util import strings
from bripipetools.io import labels
from bripipetools.io.parsers import WorkflowParser
from bripipetools.globusgalaxy.annotation import GlobusOutputAnnotator

class BatchCurator(object):
    def __init__(self, batch_submit_file, flowcell_dir=None):
        """
        Controls operations (identification, annotation, etc.) for the set of
        outputs generated by a batch processing job in Globus Galaxy.

        :type batch_submit_file: str
        :param batch_submit_file: File path of the batch submit file.

        :type flowcell_dir: str
        :param flowcell_dir: Path to flowcell folder where outputs are to be
            stored; if not specified, assumed to be one level up from folder
            containing ``batch_submit_file``.
        """
        self.submit_file = batch_submit_file
        if flowcell_dir is None:
            self.fc_dir = os.path.dirname(os.path.dirname(self.submit_file))
        else:
            self.fc_dir = flowcell_dir

    def _match_sample_project(self, sample_output_map, sample):
        """
        For a selected sample, check the location of the workflow log output
        file to determine the correct project folder.

        :type sample_output_map: dict
        :param sample_output_map: Dict mapping samples to expected output
            files in the flowcell folder.

        :type sample: str
        :param sample: Name of current sample (i.e., a key in the
            sample-to-output mapping dictionary)

        :rtype: str
        :return: File path of project folder for the current sample.
        """
        log_file = sample_output_map[sample].get('workflow_log_txt')
        project_folder = strings.matchdefault('Project_[^/]*', log_file)
        return os.path.join(self.fc_dir, project_folder)

    def curate_outputs(self):
        """
        For each sample in the processed batch, identify and classify each
        output file present in the flowcell folder.

        :rtype: dict
        :return: A dict, where for each ``sample``, output files are detailed
            and grouped by source.
        """
        wp = WorkflowParser(self.submit_file)
        workflow_name = wp.get_workflow_name()
        sample_output_map = wp.get_batch_outputs()

        sample_output_info = {}
        for idx, sample in enumerate(sample_output_map):
            project_dir = self._match_sample_project(sample_output_map, sample)
            # TODO: might want to store project folder somewhere
            project_id, subproject_id = labels.get_project_id(project_dir)

            print('\nWorkflow: {}'.format(workflow_name))
            print('>> Compiling ouputs for {} [P{}-{}] ({} of {})\n'
                  .format(sample, project_id, subproject_id,
                          idx + 1, len(sample_output_map)))

            goa = annotation.GlobusOutputAnnotator(sample_output_map, sample)
            sample_output_info.setdefault(sample, []).append(
                goa.get_output_info())
        return sample_output_info

    def organize_files(self, target_dir, sample_output_info=None):
        """
        For the outputs identified, rename and reorganize files as needed.

        :type target_dir: str
        :param target_dir: path to folder where final output files are to be
            saved
        """
        if sample_output_info is None:
            sample_output_info = self.curate_outputs()

        for source in sample_output_info:
            fm = FileMunger(self, target_dir, source)
            fm.go()
        # TODO: return something...
