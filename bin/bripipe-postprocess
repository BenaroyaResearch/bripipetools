#!/usr/bin/env python

import logging
import os
import sys

import argparse

from bripipetools import postprocess

def parse_input_args(parser=None):
    parser.add_argument('-p', '--processed_project_path',
                        required=True,
                        default=None,
                        help=("path to processed directory - e.g., "
                              "/mnt/genomics/Illumina/"
                              "150218_D00565_0081_BC5UF5ANXX/"
                              "Project_P69Processed"))
    parser.add_argument('-t', '--output_type',
                        default='a',
                        choices=['c', 'm', 'q', 'v', 'a'],
                        help=("Select type of result file to combine: "
                              "c [counts], m [metrics], q [qc], "
                              "v [validation], a [all]"))
    parser.add_argument('-s', '--stitch_only',
                        action='store_true',
                        help=("Do NOT compile and merge all summary "
                              "(non-count) data into a single file at "
                              "the project level"))
    parser.add_argument('-c', '--clean_outputs',
                        action='store_true',
                        help=("Attempt to clean/organize output files"))
    parser.add_argument('-d', '--debug',
                        action='store_true',
                        help=("Set logging level to debug"))

    # Parse and collect input arguments
    args = parser.parse_args()

    return parser.parse_args()

def main(argv):
    parser = argparse.ArgumentParser()
    args = parse_input_args(parser)

    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    if args.clean_outputs:
        logging.info("cleaning output files for {}"
                     .format(args.processed_project_path))
        path = args.processed_project_path
        postprocess.OutputCleaner(path).clean_outputs()

    logger.info("combining output files for {} with option '{}'"
                .format(args.processed_project_path, args.output_type))

    combined_paths = []
    if args.output_type in ['c', 'a']:
        logger.info("generating combined counts file")
        path = os.path.join(args.processed_project_path, 'counts')
        postprocess.OutputStitcher(path).write_table()

    if args.output_type in ['m', 'a']:
        logger.info("generating combined metrics file")
        path = os.path.join(args.processed_project_path, 'metrics')
        combined_paths.append(postprocess.OutputStitcher(path).write_table())

    if args.output_type in ['q', 'a']:
        logger.info("generating combined QC file(s)")
        path = os.path.join(args.processed_project_path, 'QC')
        postprocess.OutputStitcher(path).write_overrepresented_seq_table()
        combined_paths.append(postprocess.OutputStitcher(path).write_table())

    if args.output_type in ['v', 'a']:
        logger.info("generating combined validation file(s)")
        path = os.path.join(args.processed_project_path, 'validation')
        combined_paths.append(postprocess.OutputStitcher(path).write_table())

    if not args.stitch_only:
        logger.info("merging all combined summary data tables")
        postprocess.OutputCompiler(combined_paths).write_table()

if __name__ == "__main__":
   main(sys.argv[1:])
